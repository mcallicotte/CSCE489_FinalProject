{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Final Project - Undergraduate\n",
        "By: Mary Callicotte and Bryan White"
      ],
      "metadata": {
        "id": "_Dn9HwLw8pGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Goals\n",
        "Our goal is to explore how different features affect the performace of machine learning. We will be using this [credit risk assessment dataset](https://archive.ics.uci.edu/ml/datasets/Credit+Approval) to explore how each feature affects the performace of a Random Forest Classifer."
      ],
      "metadata": {
        "id": "2y5_GzWU89cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 0\n",
        "# Global Variables\n",
        "seed = 16112022"
      ],
      "metadata": {
        "id": "_KPkVR2dIJbC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1: Upload dataset"
      ],
      "metadata": {
        "id": "3YqivAug91HZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LfALe8MQ8kIP",
        "outputId": "1c69239d-331c-4894-e166-5a31f44af3b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    0      1       2  3  4   5   6     7  8  9   10 11 12     13   14 15\n",
              "0    b  30.83   0.000  u  g   w   v  1.25  t  t   1  f  g  202.0    0  +\n",
              "1    a  58.67   4.460  u  g   q   h  3.04  t  t   6  f  g   43.0  560  +\n",
              "2    a  24.50   0.500  u  g   q   h  1.50  t  f   0  f  g  280.0  824  +\n",
              "3    b  27.83   1.540  u  g   w   v  3.75  t  t   5  t  g  100.0    3  +\n",
              "4    b  20.17   5.625  u  g   w   v  1.71  t  f   0  f  s  120.0    0  +\n",
              "..  ..    ...     ... .. ..  ..  ..   ... .. ..  .. .. ..    ...  ... ..\n",
              "685  b  21.08  10.085  y  p   e   h  1.25  f  f   0  f  g  260.0    0  -\n",
              "686  a  22.67   0.750  u  g   c   v  2.00  f  t   2  t  g  200.0  394  -\n",
              "687  a  25.25  13.500  y  p  ff  ff  2.00  f  t   1  t  g  200.0    1  -\n",
              "688  b  17.92   0.205  u  g  aa   v  0.04  f  f   0  f  g  280.0  750  -\n",
              "689  b  35.00   3.375  u  g   c   h  8.29  f  f   0  t  g    0.0    0  -\n",
              "\n",
              "[653 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da5bcb05-4847-4c2a-9230-fdacb6e531a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>30.83</td>\n",
              "      <td>0.000</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.25</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>202.0</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>58.67</td>\n",
              "      <td>4.460</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>3.04</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>6</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>43.0</td>\n",
              "      <td>560</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>24.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>1.50</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>280.0</td>\n",
              "      <td>824</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.540</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>3.75</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>20.17</td>\n",
              "      <td>5.625</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.71</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685</th>\n",
              "      <td>b</td>\n",
              "      <td>21.08</td>\n",
              "      <td>10.085</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>e</td>\n",
              "      <td>h</td>\n",
              "      <td>1.25</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>260.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>686</th>\n",
              "      <td>a</td>\n",
              "      <td>22.67</td>\n",
              "      <td>0.750</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>c</td>\n",
              "      <td>v</td>\n",
              "      <td>2.00</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>2</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>200.0</td>\n",
              "      <td>394</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>687</th>\n",
              "      <td>a</td>\n",
              "      <td>25.25</td>\n",
              "      <td>13.500</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>ff</td>\n",
              "      <td>ff</td>\n",
              "      <td>2.00</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>200.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688</th>\n",
              "      <td>b</td>\n",
              "      <td>17.92</td>\n",
              "      <td>0.205</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>aa</td>\n",
              "      <td>v</td>\n",
              "      <td>0.04</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>280.0</td>\n",
              "      <td>750</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>b</td>\n",
              "      <td>35.00</td>\n",
              "      <td>3.375</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>c</td>\n",
              "      <td>h</td>\n",
              "      <td>8.29</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>653 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da5bcb05-4847-4c2a-9230-fdacb6e531a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da5bcb05-4847-4c2a-9230-fdacb6e531a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da5bcb05-4847-4c2a-9230-fdacb6e531a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#Task 1\n",
        "import pandas as pd\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\"\n",
        "nameArray = range(0, 16)\n",
        "df = pd.read_csv(url, header=None, names=nameArray, na_values=\"?\", index_col=False)\n",
        "df = df.dropna()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2: Prepare 5-fold Validation sets"
      ],
      "metadata": {
        "id": "m5CfI_Z8Fbly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2\n",
        "# requires task 1\n",
        "\n",
        "\n",
        "#convert data from strings\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "for column_name in df.columns:\n",
        "        if df[column_name].dtype == object:\n",
        "            df.loc[:, column_name] = le.fit_transform(df[column_name])\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "#does not use the cross validation method I found\n",
        "labels = df[15]\n",
        "labels =labels.replace(\"+\", 1)\n",
        "labels =labels.replace(\"-\", 0)\n",
        "\n",
        "\n",
        "features = df[range(0, 15)]\n",
        "\n",
        "# K-Fold Cross-Validation\n",
        "from sklearn.model_selection import cross_validate\n",
        "def cross_validation(model, _X, _y, summaryPrint = True, detailedPrint = False, _cv=5):\n",
        "    '''Function to perform 5 Folds Cross-Validation\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: Python Class, default=None\n",
        "        This is the machine learning algorithm to be used for training.\n",
        "    _X: array\n",
        "        This is the matrix of features.\n",
        "     _y: array\n",
        "        This is the target variable.\n",
        "    _cv: int, default=5\n",
        "        Determines the number of folds for cross-validation.\n",
        "    Returns\n",
        "    -------\n",
        "        The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
        "        'recall', 'f1' for both training set and validation set.\n",
        "    '''\n",
        "    _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
        "    results = cross_validate(estimator=model,\n",
        "                            X=_X,\n",
        "                            y=_y,\n",
        "                            cv=_cv,\n",
        "                            scoring=_scoring,\n",
        "                            return_train_score=True)\n",
        "      #using print because newlines looks nicer (you can undo this if you want)\n",
        "    if (summaryPrint):\n",
        "        print(\"\\tMean Validation Accuracy:\", results['test_accuracy'].mean(),\n",
        "              \"\\n\\t Max Validation Accuracy:\", results['test_accuracy'].max(),\n",
        "              \"\\n\\n\\tMean Validation Precision:\", results['test_precision'].mean(),\n",
        "              \"\\n\\t Max Validation Precision:\", results['test_precision'].max(),\n",
        "              \"\\n\\n\\tMean Validation Recall:\", results['test_recall'].mean(),\n",
        "              \"\\n\\t Max Validation Recall:\", results['test_recall'].max(),\n",
        "              \"\\n\\n\\tMean Validation F1 Score:\", results['test_f1'].mean(),\n",
        "              \"\\n\\t Max Validation F1 Score:\", results['test_f1'].max())\n",
        "    \n",
        "    if(detailedPrint):\n",
        "        print(\"Training Accuracy scores: \", results['train_accuracy'],\n",
        "              \"\\nMean Training Accuracy:\", results['train_accuracy'].mean()*100,\n",
        "              \"\\nTraining Precision scores:\", results['train_precision'],\n",
        "              \"\\nMean Training Precision:\", results['train_precision'].mean(),\n",
        "              \"\\nTraining Recall scores:\", results['train_recall'],\n",
        "              \"\\nMean Training Recall:\", results['train_recall'].mean(),\n",
        "              \"\\nTraining F1 scores:\", results['train_f1'],\n",
        "              \"\\nMean Training F1 Score:\", results['train_f1'].mean(),\n",
        "              \"\\nValidation Accuracy scores:\", results['test_accuracy'],\n",
        "              \"\\nMean Validation Accuracy:\", results['test_accuracy'].mean()*100,\n",
        "              \"\\nValidation Precision scores:\", results['test_precision'],\n",
        "              \"\\nMean Validation Precision:\", results['test_precision'].mean(),\n",
        "              \"\\nValidation Recall scores:\", results['test_recall'],\n",
        "              \"\\nMean Validation Recall:\", results['test_recall'].mean(),\n",
        "              \"\\nValidation F1 scores:\", results['test_f1'],\n",
        "              \"\\nMean Validation F1 Score:\", results['test_f1'].mean())\n",
        "      \n",
        "    return {\"Training Accuracy scores\": results['train_accuracy'],\n",
        "            \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
        "            \"Training Precision scores\": results['train_precision'],\n",
        "            \"Mean Training Precision\": results['train_precision'].mean(),\n",
        "            \"Training Recall scores\": results['train_recall'],\n",
        "            \"Mean Training Recall\": results['train_recall'].mean(),\n",
        "            \"Training F1 scores\": results['train_f1'],\n",
        "            \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
        "            \"Validation Accuracy scores\": results['test_accuracy'],\n",
        "            \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
        "            \"Validation Precision scores\": results['test_precision'],\n",
        "            \"Mean Validation Precision\": results['test_precision'].mean(),\n",
        "            \"Validation Recall scores\": results['test_recall'],\n",
        "            \"Mean Validation Recall\": results['test_recall'].mean(),\n",
        "            \"Validation F1 scores\": results['test_f1'],\n",
        "            \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
        "            }\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "modelRFC = RandomForestClassifier(random_state = seed)\n",
        "\n",
        "#https://stackoverflow.com/questions/30384995/randomforestclassfier-fit-valueerror-could-not-convert-string-to-float\n",
        "#You may not pass str to fit this kind of classifier.\n",
        "\n",
        "#- = 0\n",
        "#+ = 1\n",
        "# labels =labels.replace(\"+\", 1)\n",
        "# labels =labels.replace(\"-\", 0)\n",
        "\n",
        "# #convert data from strings\n",
        "# from sklearn import preprocessing\n",
        "# le = preprocessing.LabelEncoder()\n",
        "# for column_name in features.columns:\n",
        "#         if features[column_name].dtype == object:\n",
        "#             features.loc[:, column_name] = le.fit_transform(features[column_name])\n",
        "#         else:\n",
        "#             pass\n",
        "#print(cross_validation(modelRFC, features, labels))\n",
        "RFC_result= cross_validation(modelRFC, features, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyAguUj5FjEA",
        "outputId": "09cf9c31-abfb-46c8-a1ca-eebb41ad8851"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tMean Validation Accuracy: 0.8544920728126835 \n",
            "\t Max Validation Accuracy: 0.9694656488549618 \n",
            "\n",
            "\tMean Validation Precision: 0.883855033855034 \n",
            "\t Max Validation Precision: 0.9722222222222222 \n",
            "\n",
            "\tMean Validation Recall: 0.8339201877934272 \n",
            "\t Max Validation Recall: 0.9861111111111112 \n",
            "\n",
            "\tMean Validation F1 Score: 0.8504231642414639 \n",
            "\t Max Validation F1 Score: 0.9722222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "def plot_result(x_label, y_label, plot_title, train_data, val_data):\n",
        "        '''Function to plot a grouped bar chart showing the training and validation\n",
        "          results of the ML model in each fold after applying K-fold cross-validation.\n",
        "         Parameters\n",
        "         ----------\n",
        "         x_label: str, \n",
        "            Name of the algorithm used for training e.g 'Decision Tree'\n",
        "          \n",
        "         y_label: str, \n",
        "            Name of metric being visualized e.g 'Accuracy'\n",
        "         plot_title: str, \n",
        "            This is the title of the plot e.g 'Accuracy Plot'\n",
        "         \n",
        "         train_result: list, array\n",
        "            This is the list containing either training precision, accuracy, or f1 score.\n",
        "        \n",
        "         val_result: list, array\n",
        "            This is the list containing either validation precision, accuracy, or f1 score.\n",
        "         Returns\n",
        "         -------\n",
        "         The function returns a Grouped Barchart showing the training and validation result\n",
        "         in each fold.\n",
        "        '''\n",
        "        \n",
        "        # Set size of plot\n",
        "        plt.figure(figsize=(12,6))\n",
        "        labels = [\"1st Fold\", \"2nd Fold\", \"3rd Fold\", \"4th Fold\", \"5th Fold\"]\n",
        "        X_axis = np.arange(len(labels))\n",
        "        ax = plt.gca()\n",
        "        plt.ylim(0.40000, 1)\n",
        "        plt.bar(X_axis-0.2, train_data, 0.4, color='blue', label='Training')\n",
        "        plt.bar(X_axis+0.2, val_data, 0.4, color='red', label='Validation')\n",
        "        plt.title(plot_title, fontsize=30)\n",
        "        plt.xticks(X_axis, labels)\n",
        "        plt.xlabel(x_label, fontsize=14)\n",
        "        plt.ylabel(y_label, fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "model_name = \"RFC\"\n",
        "plot_result(model_name,\n",
        "            \"Accuracy\",\n",
        "            \"Accuracy scores in 5 Folds\",\n",
        "            RFC_result[\"Training Accuracy scores\"],\n",
        "            RFC_result[\"Validation Accuracy scores\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "WdOk3oK_cB1b",
        "outputId": "a133a3e4-1bcd-4f31-a5f2-94a514c0af45"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try to make a lot of of them\n",
        "\n",
        "features_list = []\n",
        "for column_name1 in features.columns:\n",
        "    for column_name2 in features.columns:\n",
        "        features_list.append([column_name1, column_name2])\n",
        "\n",
        "import numpy as np\n",
        "meanOutput = np.empty((4, 15, 15))\n",
        "maxOutput = np.empty((4, 15, 15))\n",
        "\n",
        "for feature_names in features_list:\n",
        "    currentFeatures = df[feature_names]\n",
        "    modelRFC = RandomForestClassifier(random_state = seed)\n",
        "    if (feature_names[1] == 14):\n",
        "        print(feature_names)\n",
        "    else:\n",
        "        print(feature_names, end = \", \")\n",
        "    RFCResult = cross_validation(modelRFC, currentFeatures, labels, False)\n",
        "    meanOutput[0][feature_names[0]][feature_names[1]] = RFCResult['Validation Accuracy scores'].mean()\n",
        "    meanOutput[1][feature_names[0]][feature_names[1]] = RFCResult['Validation Precision scores'].mean()\n",
        "    meanOutput[2][feature_names[0]][feature_names[1]] = RFCResult['Validation Recall scores'].mean()\n",
        "    meanOutput[3][feature_names[0]][feature_names[1]] = RFCResult['Validation F1 scores'].mean()\n",
        "\n",
        "    maxOutput[0][feature_names[0]][feature_names[1]] = RFCResult['Validation Accuracy scores'].max()\n",
        "    maxOutput[1][feature_names[0]][feature_names[1]] = RFCResult['Validation Precision scores'].max()\n",
        "    maxOutput[2][feature_names[0]][feature_names[1]] = RFCResult['Validation Recall scores'].max()\n",
        "    maxOutput[3][feature_names[0]][feature_names[1]] = RFCResult['Validation F1 scores'].max()\n",
        "\n",
        "\n",
        "# for i in range(0,4):\n",
        "#     print(meanOutput[i])\n",
        "#     print(maxOutput[i], end=\"\\n\\n\")"
      ],
      "metadata": {
        "id": "2t6W9d37PzZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc5a58d-398d-4415-a15d-b0e9fbf94add"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [0, 13], [0, 14]\n",
            "[1, 0], [1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [1, 13], [1, 14]\n",
            "[2, 0], [2, 1], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [2, 13], [2, 14]\n",
            "[3, 0], [3, 1], [3, 2], [3, 3], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [3, 13], [3, 14]\n",
            "[4, 0], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 13], [4, 14]\n",
            "[5, 0], [5, 1], [5, 2], [5, 3], [5, 4], [5, 5], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [5, 13], [5, 14]\n",
            "[6, 0], [6, 1], [6, 2], [6, 3], [6, 4], [6, 5], [6, 6], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [6, 13], [6, 14]\n",
            "[7, 0], [7, 1], [7, 2], [7, 3], [7, 4], [7, 5], [7, 6], [7, 7], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [7, 13], [7, 14]\n",
            "[8, 0], [8, 1], [8, 2], [8, 3], [8, 4], [8, 5], [8, 6], [8, 7], [8, 8], [8, 9], [8, 10], [8, 11], [8, 12], [8, 13], [8, 14]\n",
            "[9, 0], [9, 1], [9, 2], [9, 3], [9, 4], [9, 5], [9, 6], [9, 7], [9, 8], [9, 9], [9, 10], [9, 11], [9, 12], [9, 13], [9, 14]\n",
            "[10, 0], [10, 1], [10, 2], [10, 3], [10, 4], [10, 5], [10, 6], [10, 7], [10, 8], [10, 9], [10, 10], [10, 11], [10, 12], [10, 13], [10, 14]\n",
            "[11, 0], [11, 1], [11, 2], [11, 3], [11, 4], [11, 5], [11, 6], [11, 7], [11, 8], [11, 9], [11, 10], [11, 11], [11, 12], [11, 13], [11, 14]\n",
            "[12, 0], [12, 1], [12, 2], [12, 3], [12, 4], [12, 5], [12, 6], [12, 7], [12, 8], [12, 9], [12, 10], [12, 11], [12, 12], [12, 13], [12, 14]\n",
            "[13, 0], [13, 1], [13, 2], [13, 3], [13, 4], [13, 5], [13, 6], [13, 7], [13, 8], [13, 9], [13, 10], [13, 11], [13, 12], [13, 13], [13, 14]\n",
            "[14, 0], [14, 1], [14, 2], [14, 3], [14, 4], [14, 5], [14, 6], [14, 7], [14, 8], [14, 9], [14, 10], [14, 11], [14, 12], [14, 13], [14, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the info out of the big arrays\n",
        "meanAcc = pd.DataFrame(meanOutput[0])\n",
        "meanPre = pd.DataFrame(meanOutput[1])\n",
        "meanRec = pd.DataFrame(meanOutput[2])\n",
        "meanF1s = pd.DataFrame(meanOutput[3])\n",
        "\n",
        "# maxAcc = pd.DataFrame(maxOutput[0])\n",
        "# maxPre = pd.DataFrame(maxOutput[1])\n",
        "# maxRec = pd.DataFrame(maxOutput[2])\n",
        "# maxF1s = pd.DataFrame(maxOutput[3])\n",
        "\n",
        "fileNameList = [\"meanAccuracy.csv\", \"meanPrecision.csv\", \"meanRecall.csv\", \"meanF1.csv\"]\n",
        "arrayList = [meanAcc, meanPre, meanRec, meanF1s]\n",
        "\n",
        "meanF1s\n",
        "\n",
        "# for i in range(0, 4):\n",
        "#     currentFile = open(fileNameList[i], 'w+')\n",
        "#     arrayList[i].to_csv(currentFile)\n",
        "\n",
        "currentFile = open(fileNameList[3], 'w+')\n",
        "arrayList[3].to_csv(currentFile)\n"
      ],
      "metadata": {
        "id": "kD4Sj0jivGlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_list2 = []\n",
        "for column_name1 in features.columns:\n",
        "    for column_name2 in features.columns:\n",
        "        features_list2.append([column_name1, column_name2,features.columns[8]])\n",
        "\n",
        "import numpy as np\n",
        "meanOutput2 = np.empty((4, 15, 15))\n",
        "maxOutput2 = np.empty((4, 15, 15))\n",
        "\n",
        "for feature_names2 in features_list2:\n",
        "    currentFeatures2 = df[feature_names]\n",
        "    modelRFC = RandomForestClassifier(random_state = seed)\n",
        "    if (feature_names[1] == 14):\n",
        "        print(feature_names)\n",
        "    else:\n",
        "        print(feature_names, end = \", \")\n",
        "    RFCResult2 = cross_validation(modelRFC, currentFeatures2, labels, False)\n",
        "    meanOutput2[0][feature_names[0]][feature_names[1]] = RFCResult2['Validation Accuracy scores'].mean()\n",
        "    meanOutput2[1][feature_names[0]][feature_names[1]] = RFCResult2['Validation Precision scores'].mean()\n",
        "    meanOutput2[2][feature_names[0]][feature_names[1]] = RFCResult2['Validation Recall scores'].mean()\n",
        "    meanOutput2[3][feature_names[0]][feature_names[1]] = RFCResult2['Validation F1 scores'].mean()\n",
        "\n",
        "    maxOutput2[0][feature_names[0]][feature_names[1]] = RFCResult2['Validation Accuracy scores'].max()\n",
        "    maxOutput2[1][feature_names[0]][feature_names[1]] = RFCResult2['Validation Precision scores'].max()\n",
        "    maxOutput2[2][feature_names[0]][feature_names[1]] = RFCResult2['Validation Recall scores'].max()\n",
        "    maxOutput2[3][feature_names[0]][feature_names[1]] = RFCResult2['Validation F1 scores'].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "BmBKhRB__jWU",
        "outputId": "d4fa7d42-cd30-41c0-b60b-89d6b3cc9315"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 8], [0, 1, 8], [0, 2, 8], [0, 3, 8], [0, 4, 8], [0, 5, 8], [0, 6, 8], [0, 7, 8], [0, 8, 8], [0, 9, 8], [0, 10, 8], [0, 11, 8], [0, 12, 8], "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9245a309af94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mRFCResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelRFC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mmeanOutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFCResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Validation Accuracy scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmeanOutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFCResult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Validation Precision scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-865cc26c5cb7>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(model, _X, _y, summaryPrint, detailedPrint, _cv)\u001b[0m\n\u001b[1;32m     45\u001b[0m                             \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_cv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                             \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_scoring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                             return_train_score=True)\n\u001b[0m\u001b[1;32m     48\u001b[0m       \u001b[0;31m#using print because newlines looks nicer (you can undo this if you want)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msummaryPrint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 289\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 289\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m             trees = [\n\u001b[1;32m    440\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             ]\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    439\u001b[0m             trees = [\n\u001b[1;32m    440\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             ]\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \"\"\"\n\u001b[1;32m    158\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# TODO: Remove in v1.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mnested_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# grouped by prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 raise ValueError(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}